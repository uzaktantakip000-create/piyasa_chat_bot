services:
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    env_file:
      - .env
    environment:
      # Veritabanı ve Redis (Postgres tercih; istersen SQLite kullanmak için bu satırı kaldır)
      - DATABASE_URL=postgresql+psycopg://app:app@db:5432/app
      - REDIS_URL=redis://redis:6379/0

      # LLM Provider ve API Keys
      - LLM_PROVIDER=${LLM_PROVIDER:-openai}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - LLM_MODEL=${LLM_MODEL:-gpt-4o-mini}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - GEMINI_MODEL=${GEMINI_MODEL:-gemini-1.5-flash}
      - GROQ_API_KEY=${GROQ_API_KEY}
      - GROQ_MODEL=${GROQ_MODEL:-llama-3.3-70b-versatile}

      # Telegram
      - TELEGRAM_API_BASE=${TELEGRAM_API_BASE:-https://api.telegram.org}
      - TELEGRAM_TIMEOUT=${TELEGRAM_TIMEOUT:-20}

      # Genel
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PORT=8000
    ports:
      - "8000:8000"
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started

  # ============================================================================
  # WORKER 1 (Bot ID % 4 == 0)
  # ============================================================================
  worker-1:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: piyasa_worker_1
    env_file:
      - .env
    environment:
      - DATABASE_URL=postgresql+psycopg://app:app@db:5432/app
      - REDIS_URL=redis://redis:6379/0
      # Multi-worker coordination
      - WORKER_ID=0
      - TOTAL_WORKERS=4
      # LLM Provider ve API Keys
      - LLM_PROVIDER=${LLM_PROVIDER:-openai}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - LLM_MODEL=${LLM_MODEL:-gpt-4o-mini}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - GEMINI_MODEL=${GEMINI_MODEL:-gemini-1.5-flash}
      - GROQ_API_KEY=${GROQ_API_KEY}
      - GROQ_MODEL=${GROQ_MODEL:-llama-3.3-70b-versatile}
      # Telegram
      - TELEGRAM_API_BASE=${TELEGRAM_API_BASE:-https://api.telegram.org}
      - TELEGRAM_TIMEOUT=${TELEGRAM_TIMEOUT:-20}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    command: ["python", "worker.py"]
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started
    restart: unless-stopped

  # ============================================================================
  # WORKER 2 (Bot ID % 4 == 1)
  # ============================================================================
  worker-2:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: piyasa_worker_2
    env_file:
      - .env
    environment:
      - DATABASE_URL=postgresql+psycopg://app:app@db:5432/app
      - REDIS_URL=redis://redis:6379/0
      # Multi-worker coordination
      - WORKER_ID=1
      - TOTAL_WORKERS=4
      # LLM Provider ve API Keys
      - LLM_PROVIDER=${LLM_PROVIDER:-openai}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - LLM_MODEL=${LLM_MODEL:-gpt-4o-mini}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - GEMINI_MODEL=${GEMINI_MODEL:-gemini-1.5-flash}
      - GROQ_API_KEY=${GROQ_API_KEY}
      - GROQ_MODEL=${GROQ_MODEL:-llama-3.3-70b-versatile}
      # Telegram
      - TELEGRAM_API_BASE=${TELEGRAM_API_BASE:-https://api.telegram.org}
      - TELEGRAM_TIMEOUT=${TELEGRAM_TIMEOUT:-20}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    command: ["python", "worker.py"]
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started
    restart: unless-stopped

  # ============================================================================
  # WORKER 3 (Bot ID % 4 == 2)
  # ============================================================================
  worker-3:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: piyasa_worker_3
    env_file:
      - .env
    environment:
      - DATABASE_URL=postgresql+psycopg://app:app@db:5432/app
      - REDIS_URL=redis://redis:6379/0
      # Multi-worker coordination
      - WORKER_ID=2
      - TOTAL_WORKERS=4
      # LLM Provider ve API Keys
      - LLM_PROVIDER=${LLM_PROVIDER:-openai}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - LLM_MODEL=${LLM_MODEL:-gpt-4o-mini}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - GEMINI_MODEL=${GEMINI_MODEL:-gemini-1.5-flash}
      - GROQ_API_KEY=${GROQ_API_KEY}
      - GROQ_MODEL=${GROQ_MODEL:-llama-3.3-70b-versatile}
      # Telegram
      - TELEGRAM_API_BASE=${TELEGRAM_API_BASE:-https://api.telegram.org}
      - TELEGRAM_TIMEOUT=${TELEGRAM_TIMEOUT:-20}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    command: ["python", "worker.py"]
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started
    restart: unless-stopped

  # ============================================================================
  # WORKER 4 (Bot ID % 4 == 3)
  # ============================================================================
  worker-4:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: piyasa_worker_4
    env_file:
      - .env
    environment:
      - DATABASE_URL=postgresql+psycopg://app:app@db:5432/app
      - REDIS_URL=redis://redis:6379/0
      # Multi-worker coordination
      - WORKER_ID=3
      - TOTAL_WORKERS=4
      # LLM Provider ve API Keys
      - LLM_PROVIDER=${LLM_PROVIDER:-openai}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - LLM_MODEL=${LLM_MODEL:-gpt-4o-mini}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - GEMINI_MODEL=${GEMINI_MODEL:-gemini-1.5-flash}
      - GROQ_API_KEY=${GROQ_API_KEY}
      - GROQ_MODEL=${GROQ_MODEL:-llama-3.3-70b-versatile}
      # Telegram
      - TELEGRAM_API_BASE=${TELEGRAM_API_BASE:-https://api.telegram.org}
      - TELEGRAM_TIMEOUT=${TELEGRAM_TIMEOUT:-20}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    command: ["python", "worker.py"]
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started
    restart: unless-stopped

  db:
    image: postgres:16-alpine
    environment:
      - POSTGRES_USER=app
      - POSTGRES_PASSWORD=app
      - POSTGRES_DB=app
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U app -d app || exit 1"]
      interval: 5s
      timeout: 3s
      retries: 10
    volumes:
      - pgdata:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    command: ["redis-server","--save","","--appendonly","no"]
    ports:
      - "6379:6379"

  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    env_file:
      - .env
    ports:
      - "5173:5173"
    depends_on:
      - api

  # ============================================================================
  # PROMETHEUS - Metrik Toplama (Gösterge Paneli Arka Plan Servisi)
  # ============================================================================
  prometheus:
    image: prom/prometheus:latest
    container_name: piyasa-prometheus
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"  # Prometheus UI: http://localhost:9090
    depends_on:
      - api
    restart: unless-stopped

  # ============================================================================
  # GRAFANA - Metrik Görselleştirme (Gösterge Paneli Ekranı)
  # ============================================================================
  grafana:
    image: grafana/grafana:latest
    container_name: piyasa-grafana
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
    ports:
      - "3000:3000"  # Grafana UI: http://localhost:3000 (admin/admin)
    depends_on:
      - prometheus
    restart: unless-stopped

volumes:
  pgdata:
  prometheus-data:  # Prometheus verilerini saklar
  grafana-data:     # Grafana dashboardlarını saklar
